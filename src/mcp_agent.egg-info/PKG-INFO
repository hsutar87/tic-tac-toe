Metadata-Version: 2.4
Name: mcp-agent
Version: 0.1.0
Summary: A witty, concise RAG agent using FastMCP, OpenSearch, and Ollama
Author: Harish Sutar
Project-URL: Repository, https://github.com/hsutar87/mcp-agent
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests>=2.31.0
Requires-Dist: ollama>=0.4.7
Requires-Dist: fastmcp>=0.4.1
Requires-Dist: opensearch-py>=3.1.0
Requires-Dist: pymupdf>=1.24.0
Requires-Dist: python-docx>=1.1.0
Requires-Dist: langchain-text-splitters>=0.2.0
Requires-Dist: uvicorn>=0.30.0
Requires-Dist: python-dotenv>=1.2.1
Requires-Dist: tqdm>=4.65.0
Requires-Dist: colored>=2.3.1
Dynamic: license-file

# ğŸ’ƒ Silly Agent: Witty, Concise, and Dangerous

> â€œInformation is a heavy burden; let me carry it for you. Just donâ€™t expect me to be nice about it.â€ â€” **Silly**

Silly Agent is a local, RAG-powered AI assistant that is sharp, concise, and context-aware. It retrieves answers from your local documents using OpenSearch vectors and Ollama embeddings, and exposes tools via FastMCP.

---

## âœ¨ Features

- Local RAG with OpenSearch vector index
- FastMCP tool server (SSE transport)
- Witty persona with short answers
- Sliding-window conversation memory
- Ollama embeddings + LLM (local inference)

---

## ğŸ›  Prerequisites

- Python 3.10+
- OpenSearch running locally (HTTPS)
- Ollama installed with required models
- `uv` (optional, recommended)

---

## ğŸ”¥ OpenSearch Verification
```bash
curl -k -u <USER>:<PASS> https://localhost:9200
```
## ğŸ§© Ollama Models
```bash
ollama pull deepseek-r1:8b
ollama pull mxbai-embed-large
```

---

## ğŸš€ Installation

```bash
git clone https://github.com/hsutar87/mcp-agent.git
cd mcp-agent
uv sync
```

Or with pip:

```bash
pip install -e .
```

---

## ğŸ” Environment Variables

Create a `.env` file:

```env
OPENSEARCH_USER=admin
OPENSEARCH_PASS=<YOUR_PASS>
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200
```

Add `.env` to `.gitignore`.

---

## ğŸ§¾ CA Certificate (Ubuntu)

```bash
sudo cp /etc/opensearch/root-ca.pem ./root-ca.pem
sudo chown $USER:$USER ./root-ca.pem
```

---

## ğŸ“– Usage

### 1. Start the MCP Server

```bash
uv run python -m src.mcp_server
```

### 2. Ingest Documents

Put PDFs/DOCX/TXT in `data/` and run:

```bash
uv run python main.py --ingest
```

### 3. Chat

```bash
uv run python main.py
```

---

## ğŸ’¬ Commands

* `clear`: wipe memory
* `exit` / `quit`: exit
* Normal text: ask a question

---

## ğŸ“‚ Project Structure

* `src/reader.py` â€” file parsing
* `src/vector_store.py` â€” OpenSearch + Ollama embeddings
* `src/memory.py` â€” conversation memory
* `src/agent.py` â€” agent logic
* `src/mcp_server.py` â€” FastMCP tools
* `main.py` â€” ingestion + chat loop

---

## ğŸ§ª Tool Test (Optional)

```bash
curl -s http://localhost:8000/execute/search_local_docs \
  -d '{"query":"capital of France","limit":5}' \
  -H "Content-Type: application/json"

---
## ğŸ“ License
This project is licensed under the [MIT License](LICENSE).
